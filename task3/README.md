# Задача 3
Реализация параллельного алгоритма Кэннона для умножения двух квадратных матриц A и B размером N×N с целью получения матрицы C = A × B.

# Основные характеристики:
   - Используется двумерная декартова топология MPI (сетка процессов p×p)
   - Матрицы разбиваются на блоки размером (N/p)×(N/p)
   - Время работы: O(N³/p) при O(√p) процессорах
   - Коммуникационная сложность: O(N²/√p)

# Этапы алгоритма:
   1. Инициализация и распределение данных
   2. Предварительный сдвиг блоков (Initial Alignment)
   3. Основной цикл с циклическими сдвигами (q итераций, где q=√p)
   4. Сборка результата
   5. Проверка корректности и вывод статистики

# Таблица времени параллельного выполнения (сек)

| Размер матрицы/Процессы| 1     | 4     | 9     | 16    | 25    | 36    | 64    | 100   |
| -------------- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- |
| 200            | 0.015 | 0.004 | -     | 0.007 | 0.008 | -     | 0.050 | 0.344 |
| 400            | 0.224 | 0.032 | -     | 0.050 | 0.042 | -     | 0.071 | 0.106 |
| 600            | 0.386 | 0.137 | 0.189 | 0.136 | 0.127 | 0.132 | 0.160 | 0.220 |
| 800            | 1.055 | 0.416 | -     | 0.260 | 0.342 | -     | 0.325 | 0.328 |
| 1000           | 2.521 | 1.125 | -     | 0.541 | 0.599 | -     | 0.651 | 0.774 |

# Таблица ускорения

| Размер матрицы/Процессы | 1    | 4    | 9    | 16   | 25   | 36   | 64   | 100  |
| -------------- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
| 200            | 0.91 | 2.72 | -    | 1.72 | 1.35 | -    | 0.24 | 0.04 |
| 400            | 1.17 | 2.82 | -    | 4.09 | 2.15 | -    | 1.80 | 0.86 |
| 600            | 0.77 | 2.23 | 1.82 | 2.52 | 2.44 | 2.48 | 1.88 | 3.11 |
| 800            | 1.06 | 2.74 | -    | 4.05 | 3.19 | -    | 3.34 | 3.81 |
| 1000           | 0.98 | 2.27 | -    | 4.73 | 4.26 | -    | 3.87 | 2.99 |

# График зависимости времени от размера матрицы
<img width="2400" height="1600" alt="image" src="https://github.com/user-attachments/assets/883226f5-0956-4f71-bed4-59b60a2b7e59" />

# График зависимости ускорения от размера матрицы
<img width="2400" height="1600" alt="image" src="https://github.com/user-attachments/assets/6bda5be4-e9f7-40a5-9f54-3f7ac0f2d087" />

# График зависимости времени от количества процессов при различных размерностях
<img width="2400" height="1600" alt="image" src="https://github.com/user-attachments/assets/e5c483c3-757f-40fe-ba7f-0718cbe8c851" />

# График зависимости ускорения количества процессов при различных размерностях
<img width="2400" height="1600" alt="image" src="https://github.com/user-attachments/assets/3dc191eb-038a-47d8-8553-8f911f9c20bc" />


# Можно сделать следующие выводы:
- График времени параллельного выполнения показывает, что время растет с увеличением размерности матрицы и снижается с увеличением числа процессов, но неравномерно из-за накладных расходов.
- График показывает, что время уменьшается с ростом числа процессов, но с некоторыми аномалиями для маленьких размерностей и больших чисел процессов, где время может возрастать из-за накладных расходов.
- Для больших матриц (800, 1000) наблюдается заметное снижение времени с увеличением процессов до примерно 25-64, после чего уменьшение замедляется.
- Для всех размеров матриц ускорение растёт с числом процессов, но не пропорционально. Лучшее ускорение достигается при больших размерностях и умеренном количестве процессов (например, 16-25), а при слишком большом числе процессов ускорение падает из-за затрат на коммуникацию.
- Ускорение обычно растет с ростом процессов, достигая максимума при умеренном числе процессов, но часто падает при слишком больших их числах из-за коммуникационных и организационных расходов.
- Для размерностей 400, 800, 1000 максимальное ускорение достигается в диапазоне 16-25 процессов.
  


